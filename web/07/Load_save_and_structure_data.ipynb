{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 07: Working with structured data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829ef88",
   "metadata": {},
   "source": [
    "[Download on GitHub](https://github.com/NumEconCopenhagen/lectures-2022)\n",
    "\n",
    "[<img src=\"https://mybinder.org/badge_logo.svg\">](https://mybinder.org/v2/gh/NumEconCopenhagen/lectures-2022/master?urlpath=lab/tree/07/Load_save_and_structure_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0969b",
   "metadata": {},
   "source": [
    "1. [Pandas dataframes](#Pandas-dataframes)\n",
    "2. [Reading and writing data](#Reading-and-writing-data)\n",
    "3. [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before we begin, let's first take a quick [survey on the Inaugural assignment](https://forms.office.com/Pages/ResponsePage.aspx?id=kX-So6HNlkaviYyfHO_6kckJrnVYqJlJgGf8Jm3FvY9UMEZTODYyVjJWSFBPNTVRMzBMQzFYOE5JQiQlQCN0PWcu)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By and large, handling data sets in Python means working with **Pandas**.  \n",
    "\n",
    "Pandas is a standard element in the Anaconda package, so you'll have it automatically.  \n",
    "\n",
    "The fact that Python is a general purpose language *and* has a good way of handling data sets through pandas has helped it become such a popular language for scientific and general purposes.  \n",
    "\n",
    "Today, you will learn about\n",
    "1. the pandas **data frame** object and the **pandas series**. \n",
    "2. how to **load and save data** both to and from offline sources (e.g. CSV or Excel). \n",
    "3. and how to clean, rename, structure and index your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Links:**\n",
    "\n",
    "1. Official [tutorials](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html)\n",
    "2. DataCamp's [pandas' cheat sheet](https://www.datacamp.com/community/blog/python-pandas-cheat-sheet)\n",
    "3. DataCamp has additional courses on pandas like [Writing efficient code with pandas](https://app.datacamp.com/learn/courses/writing-efficient-code-with-pandas).\n",
    "4. About the [pandas project](https://pandas.pydata.org/about/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Pandas-dataframes\"></a>\n",
    "\n",
    "# 1. Pandas dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, the fundamental object of interest is a **pandas dataframe**. \n",
    "\n",
    "A pandas data frame is superficially like the data frames you know from stata and sas: it is in 2-d, each column has a name. \n",
    "\n",
    "The *data type* of a column in a pandas data frame is a **pandas series**.\n",
    "\n",
    "A pandas series is **a lot like a numpy array** and they can be used in much the same way.  \n",
    "\n",
    "A pandas data frame can be thought of as a **dictionary of pandas series**. (Keys are column names) \n",
    "\n",
    "To create a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.Series([1, 2, 3])\n",
    "incs = pd.Series([11.7, 13.9, 14.6])\n",
    "names = pd.Series(['Vitus', 'Maximilian', 'Bo-bob'])\n",
    "\n",
    "# Use data frame definition\n",
    "X = pd.DataFrame({'id': ids, 'inc':incs, 'name': names})\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating a DataFrame, you can also rely on python to recast the variables into pandas series at creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables are cast into pandas series as the DataFrame is created\n",
    "X = pd.DataFrame({'id': [1, 2, 3], \n",
    "                  'inc': [11.7, 13.9, 14.6], \n",
    "                  'name': ['Vitus', 'Maximilian', 'Bo-bob']}) \n",
    "type(X['id'])                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass in data as a list of lists and provide column names as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data = [[1,11.7,'Vitus'],\n",
    "                         [2,13.9,'Maximilian'],\n",
    "                         [3,14.6,'Bo-Bob']], \n",
    "                 columns=['id','inc','name'])\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A dataframe is essentially a matrix.**\n",
    "\n",
    "* rows = observations \n",
    "* columns = variables \n",
    "* the index = keeps track of the rows' locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `object` mean?** In practice it is a `str` but it can give rise to difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can also show a dataframe in the  middle of some code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before')\n",
    "display(X)\n",
    "print('after')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Indexing (\"subsetting\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing a subset of the rows and/or columns of a dataframe is known as \"indexing\"**. \n",
    "\n",
    "Recall the stuff about ***slicing*** and ***logical indices*** from previous lectures. Since Pandas is build in Numpy, we can do the same here.  \n",
    "\n",
    "All pandas dataframes are born with the method `.loc[]` and `.iloc[]`:\n",
    "1. `.iloc[]` is for **numeric indexing** \n",
    "2. `.loc[]` for **logical** and **name-based** indexing. \n",
    "\n",
    "Examples\n",
    "* `df.iloc[0:3,1]` selects rows 0,1,2 and column 2.\n",
    "* `df.loc[:, ['year']]` selects all rows (indicated by `:`) but only the column (variable) `year`. \n",
    "* `df.loc[df['year'] == 2002, :]` selects the rows where the variable `year` is equal to 2002 and all columns (indicated by `:`)\n",
    "* `df.loc[df['year'] == 2002, ['name']]` selects the variable `name` and shows the rows where `year` is equal to 2002. \n",
    "\n",
    "*You cannot write*:  \n",
    "`df.iloc[0:2, ['year']]`  \n",
    "\n",
    "*You should not write*  \n",
    "`df.loc[0:2, ['year']]`  \n",
    "*It will only work with a numerical index and now the slice intervals are **closed instead of half open***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the **syntax** is `df.loc[CONDITION, [VARLIST]]`, where `CONDITION` is a vector of logical statements with the same length as the number of rows in the dataframe, and `VARLIST` is a list over variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use logical indexing to subset from variable name based on id\n",
    "X.loc[X['id'] > 1, ['name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset all variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X['id'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatives:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a boolean series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = X['id'] > 1\n",
    "print(I)\n",
    "X.loc[I, ['name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.VARIABLE` notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[(X.id > 1) & (X.inc > 14), ['id','name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think the `.VARIABLE` notation works at all? What does it make you suspect a variable is to the DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsetting with numerical indexing works the same way as lists and arrays.  \n",
    "**Syntax:** `df.iloc[ROW INDICES, [COLUMN INDICES]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.iloc[0:2,[0,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the **half-open** intervals!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Adding a variable\n",
    "\n",
    "Variables are added with `df['newvar'] = SOMETHING`. *The length must match or RHS is a scalar (broadcasting)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['year'] = [2003, 2005, 2010]\n",
    "X['zone'] = 7\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You canNOT write `df.newvar = SOMETHING`. Some of you will forget. I promise.  \n",
    "**Also:** note that you could add the year-variable even though it does not have an explicit row dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *something* can be an **expression based on other variables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['inc_adj'] = X.inc - X.inc.mean() + 0.1\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Assignments to a subset of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LHS:** Selected using logical statement.<br>\n",
    "**RHS:** Must either be:\n",
    "\n",
    "1. a **single value** (all rows are set to this) \n",
    "2. a **list of values** with same length as the number of selected rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple rows, one value:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of X to avoid overwriting it.\n",
    "Y = X.iloc[:,0:4].copy()\n",
    "Y.loc[Y.id > 1, ['name']] = 'no name'\n",
    "print('Y After change in names:')\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple rows, multiple values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original df:')\n",
    "Y = X.iloc[:,0:4].copy()\n",
    "display(Y)\n",
    "\n",
    "# Subset the rows, where name is Vitus or year is 2005. LHS is incidentally only 2 rows, which match the RHS!\n",
    "I = (Y.name == 'Vitus') | (Y.year == 2010)\n",
    "\n",
    "# Print LHS\n",
    "print('Subset of Y, LHS in assignment:')\n",
    "display(Y.loc[I,:])\n",
    "\n",
    "# Assignment\n",
    "Y.loc[I, ['name']] = ['Bib', 'Peter']\n",
    "\n",
    "print('Final Y:')\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Copies vs. views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the stuff about references to objects from L02 and how making changes in a reference also causes changes in the \"original\" object? Pandas sort of shields you from that trap.  \n",
    "Here is how:\n",
    "When **looking** at the data it is natural to just avoid the `.loc` (as in most other languages):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm NOT using the .loc function\n",
    "Z = Y[['id','name']]\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even make subsets without it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Y['id'] > 1\n",
    "Z[I]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, this **does not work with assignment**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1:** It does not work with views, as they are references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.copy()          # Create Y as a new instance by copying\n",
    "I = Y['id'] > 2       # Boolean index\n",
    "Z1 = Y[['id','name']] # returns a VIEW through chained assignment\n",
    "\n",
    "# We CANNOT change Z1 as it is a view of Y\n",
    "Z1.loc[I, ['name']] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But it works with Z2 \n",
    "Z2 = Y.loc[:, ['id','name']] \n",
    "Z2.loc[I, ['name']] = 'test'\n",
    "display(Z2)\n",
    "\n",
    "# Importantly, we did not change names in Y\n",
    "display(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2:** Sometimes it works, but not how you want it to.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(X)\n",
    "Y = X.copy()\n",
    "\n",
    "I = Y['id'] > 1\n",
    "Z = Y['name'] # returns a view of the column (same with Y.name)\n",
    "Z[I] = 'test' # Reassigning values to the view of name in Y\n",
    "\n",
    "## WOOPS:\n",
    "display(Y)\n",
    "display(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Do the assignment in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Y['id'] > 1\n",
    "Y.loc[I, ['name']] = 'test'\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 The index\n",
    "\n",
    "The **first column** in the dataset is referred to as the `index` of the dataframe.<br>\n",
    "**Baseline:** If you haven't done anything, it is just `[0, 1, 2, ....]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({'id': [1, 2, 3], \n",
    "                  'inc': [11.7, 13.9, 14.6], \n",
    "                  'name': ['Vitus', 'Maximilian', 'Bo-bob'],\n",
    "                  'year': [2010, 2010, 2019]}) \n",
    "\n",
    "# See the indices of X\n",
    "print(X.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom:** You can actually use any **unique** identifier. It does not have to be numbers. For example, you can assign the name column to be the index instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.set_index('name') # returns a copy\n",
    "Y # notice name is now below the other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have specified an index at creation of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({'id': [1, 2, 3], \n",
    "                  'inc': [11.7, 13.9, 14.6],\n",
    "                  'year': [2010, 2010, 2019]}, \n",
    "                  index= ['Vitus', 'Maximilian', 'Bo-bob'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use index of rows:\n",
    "Y.loc['Vitus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the indices of Y\n",
    "print(Y.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a [**quizz**](https://forms.office.com/Pages/ResponsePage.aspx?id=kX-So6HNlkaviYyfHO_6kckJrnVYqJlJgGf8Jm3FvY9UNDdSQTgzRU1XMlc3MzJEQUo5UjNCRURDSCQlQCN0PWcu) on subsetting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Series and numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you select an individual variable, it has the data type `Series`. Some functions work on a pandas series (e.g. most numpy functions), but it is sometimes nice to extract the underlying numpy objects: \n",
    "\n",
    "* `df`: **pandas dataframe** \n",
    "* `df['variable']`: **pandas series**\n",
    "* `df['variabe'].values` (or `.to_numpy()`): **numpy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way to do it\n",
    "X.inc.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way\n",
    "display(X.inc.values)\n",
    "type(X.inc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list instead\n",
    "display([*X['id'].values]) # returns a view\n",
    "display(type([*X['id'].values]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Calling functions on a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row-by-row**  \n",
    "Create function that takes row as an argument, and then **apply** the action of the function along the row dimension (axis=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({'id': [1, 2, 3], \n",
    "                  'inc': [11.7, 13.9, 14.6],\n",
    "                  'year': [2010, 2010, 2019], \n",
    "                  'name': ['Vitus', 'Maximilian', 'Bo-bob']})\n",
    "\n",
    "# Notice that row is an input argument here\n",
    "def conc_row_wise(row):\n",
    "    return str(row['year']) + ' - ' + row['name'] \n",
    "\n",
    "# The fact that row is an input argument in the conc_row_wise function is implicitly understood by .apply()\n",
    "Y['year_name'] = Y.apply(conc_row_wise, axis=1)  # Notice that axis = 1 is going down rows. Kind of confusing. \n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for numpy arrays:**  \n",
    "Use the fact that a Pandas df is based on Numpy arrays to create a function that operate on the rows.   \n",
    "This may involve broadcasting (see L03). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_at_once(inc, year):\n",
    "    return inc * year.max() # Notice that the values of a pd DataFrame column is Numpy, so it has a .max() method. \n",
    "\n",
    "Y['inc_adj_year'] = all_at_once(Y.inc.values, Y.year.values)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the assign method of DataFrames**  \n",
    "Apply the assing method coupled with a lambda function using the functionality of numpy arrays to get inplace changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.assign(inc_adj_inplace = lambda x: x.inc * x.year.max())\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Reading-and-writing-data\"></a>\n",
    "\n",
    "# 2. Reading and writing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** We make sure that we have the **data/** subfolder, and that it has the datasets we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Using assert to check that paths exist on computer. See L05 for details.\n",
    "assert os.path.isdir('data/')\n",
    "assert os.path.isfile('data/RAS200.xlsx')\n",
    "assert os.path.isfile('data/INDKP107.xlsx')\n",
    "\n",
    "# Print everything in data\n",
    "os.listdir('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers a lot of facilities for **reading and writing to different formats**. The functions have logical names: \n",
    "\n",
    "* CSV: `pd.read_csv()`\n",
    "* SAS: `pd.read_sas()`\n",
    "* Excel: `pd.read_excel()`\n",
    "* Stata: `pd.read_stata()`\n",
    "* Parquet: `pd.read_parquet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting:** \n",
    "\n",
    "* `df.head(10)` is ued to inspect the first 10 rows\n",
    "* `df.sample(10)` is ued to look at 10 random rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Raw download from DST  \n",
    "\n",
    "Clearly not quite right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/RAS200.xlsx' # open the file and have a look at it\n",
    "pd.read_excel(filename).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to clean this **mess** up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the right columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skipping rows:** Clearly, we should **skip** the first three rows and the first four columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl = pd.read_excel(filename, skiprows=2)\n",
    "empl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping columns:** The first couple of columns are not needed and contain only missing values (denoted by `NaN` (not-a-number)), so we will drop those. \n",
    "\n",
    "**Note:** `df.drop()` is a function that the data frame object applies to itself. Hence, no return value is used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns have to go: 'Unnamed: 0' 'Unnamed: 1' 'Unnamed: 2' 'Unnamed: 3'\n",
    "drop_these = ['Unnamed: ' + str(num) for num in range(4)] # use list comprehension to create list of columns\n",
    "print(drop_these)\n",
    "empl.drop(drop_these, axis=1, inplace=True) # axis = 1 -> columns, inplace=True -> changed, no copy made\n",
    "empl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Alternative:** Use `del empl['Unnamed: 0'], empl['Unnamed: 1']..`.  \n",
    "\n",
    "**But!** that borders on code repetition.. Would give you 4 places to make code changes rather than 2 as with the list comprehension above, in case data changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not happy with the column comprising regions, which is currently called `Unnamed: 4`.   \n",
    "\n",
    "We rename using `df.rename(columns=dict)`, where dict must be a Python *dictionary*. Why a dictionary? It is simply the most practical solution if you are renaming several columns at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.rename(columns = {'Unnamed: 4':'municipality'}, inplace=True)\n",
    "empl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rename all year columns:** We also see that the employment rate in 2008 has been named `2008`.   \n",
    "\n",
    "This is allowed in Python, but having a **variable named as a number** can cause **problems** with some functions (and many other programming languages do not even allow it), so let us change their names.   \n",
    "\n",
    "To change all columns, we need to create a dictionary that maps each of the years {2008, ..., 2016} to {e2008, ..., e2016}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {}\n",
    "for i in range(2008, 2020+1): # range goes from 2008 to but not including 2018\n",
    "    col_dict[str(i)] = f'empl{i}' \n",
    "col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.rename(columns = col_dict, inplace=True)\n",
    "empl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A big NO-NO!!** is to put *white spaces* in column names. You can theoretically have a column such as empl['e 2017'] in a pandas df, but this is *very likely* to get messy. And you can no longer use `.`notation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract:** Now we can find the employment rate in the municipality where Christian grew up: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.loc[empl.municipality == 'Hillerød']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping observations that are not actually municipalities \n",
    "\n",
    "The dataset contains observations like \"Region Hovedstaden\", which is not a municipality, so we want to drop such rows. To do this, we can use the `df['var'].str` functionalities. These are all sorts of functions that work with strings, in particular searching for instances of specific content by `df['var'].str.contains('PATTERN')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up a logical index I\n",
    "I = empl.municipality.str.contains('Region')\n",
    "I |= empl.municipality.str.contains('Province')\n",
    "I |= empl.municipality.str.contains('All Denmark')\n",
    "empl.loc[I, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete these rows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl = empl.loc[I == False] # keep everything else\n",
    "empl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very important: **reset index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.reset_index(inplace = True, drop = True) # Drop old index too\n",
    "empl.iloc[0:4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics \n",
    "\n",
    "To get an overview of employments across municipalities we can use the function `df.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single descriptive statistic:** We can also just get the mean for each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.iloc[:,1:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Long vs. wide datasets: `pd.wide_to_long()`\n",
    "\n",
    "Often in economic applications, it can be useful to switch between *wide* vs. *long* formats (long is sometimes referred to as *tall*, e.g. in Stata). This is done by the commands `pd.wide_to_long()` (and `pd.long_to_wide()`).  Many types of analysis are easier to do in one format than in another so it is extremely useful to be able to switch comfortably between formats. \n",
    "\n",
    "**Common:** Think of a dataset as having an `ID` and a `PERIOD` variable. In our dataset `empl`, the `ID` variable is `municipality`, and the `PERIOD` variable is `year`. \n",
    "\n",
    "**Wide dataset:** The default from Statistics Denmark: 1 row in data per `ID` and a variable for each `PERIOD`. If there are more than one variable per observation that varies by period, then a new block of period-wise cases must be created along columns.  \n",
    "\n",
    "**Long dataset:** There is one row for each combination of (`ID`, `PERIOD`). Vertical blocks of periods. \n",
    "\n",
    "A **long dataset** is often easier to work with if you have more than one time-varying variable in the data set. \n",
    "\n",
    "In general, Pandas will assume that the variables in the *wide* format have a particular structure: namely they are of the form `XPERIOD`, where `X` is called the \"stub\". In our case, the variable names are e.g. `e2011`, so the stub is `e` and the period (for that variable) is `2011`. You'll want to clean out the variable names if there is anything after the `period` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long = pd.wide_to_long(empl, stubnames='empl', i='municipality', j='year')\n",
    "empl_long.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The variables `municipality` and `year`  are now in the index!! We see that because they are \"below\" `e` in the `head` overview. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index variable now consists of tuples. \n",
    "print(empl_long.index.values[0:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **select a specific municipality** using ``.xs``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long.xs('Roskilde',level='municipality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or ``.loc[]`` in a special way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long.loc[empl_long.index.get_level_values('municipality') == 'Roskilde', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative:** Reset the index, and use `.loc` as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long = empl_long.reset_index()\n",
    "empl_long.loc[empl_long.municipality == 'Roskilde', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting interactively  \n",
    "A pandas DataFrame has built-in functions for plotting. Works a bit differently from matplotlib. \n",
    "\n",
    "Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame with roskilde\n",
    "empl_roskilde = empl_long.loc[empl_long['municipality'] == 'Roskilde', :]\n",
    "\n",
    "# Plot the content of the data frame\n",
    "empl_roskilde.plot(x='year',y='empl',legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even do it **interactively**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "def plot_e(df, municipality): \n",
    "    I = df['municipality'] == municipality\n",
    "    ax=df.loc[I,:].plot(x='year', y='empl', style='-o', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(plot_e, \n",
    "    df = widgets.fixed(empl_long),\n",
    "    municipality = widgets.Dropdown(description='Municipality', \n",
    "                                    options=empl_long.municipality.unique(), \n",
    "                                    value='Roskilde')\n",
    "); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Income\n",
    "\n",
    "Next, we will read in the avg. disposable income for highly educated in each municipality. Here we do the cleaning, renaming and structuring in a few condensed lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. load\n",
    "inc = pd.read_excel('data/INDKP107.xlsx', skiprows=2)\n",
    "\n",
    "# b. clean and rename\n",
    "inc.drop([f'Unnamed: {i}' for i in range(4)], axis=1, inplace=True) # using list comprehension\n",
    "inc.rename(columns = {'Unnamed: 4':'municipality'}, inplace=True) \n",
    "inc.rename(columns = {str(i): f'inc{i}' for i in range(2004,2020+1)}, inplace=True) # using dictionary comprehension\n",
    "\n",
    "# c. drop rows with missing values. Denoted na\n",
    "inc.dropna(inplace=True)\n",
    "\n",
    "# d. remove non-municipalities. Notice how to avoid code repetition!\n",
    "for val in ['Region','Province', 'All Denmark']: \n",
    "    I = inc.municipality.str.contains(val)\n",
    "    inc.drop(inc[I].index, inplace=True) # .index -> get the indexes of the series\n",
    "    \n",
    "inc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert** wide -> long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_long = pd.wide_to_long(df=inc, stubnames='inc', i='municipality', j='year')\n",
    "inc_long.reset_index(inplace=True)\n",
    "inc_long.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Municipal area\n",
    "\n",
    "Finally, let's read in a dataset on municipality areas in km$^2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. load\n",
    "area = pd.read_excel('data/areal.xlsx', skiprows=2)\n",
    "\n",
    "# b. clean and rename\n",
    "area.rename(columns = {'Unnamed: 0':'municipality','2019':'km2'}, inplace=True)\n",
    "\n",
    "# c. drop rows with missing\n",
    "area.dropna(inplace=True)\n",
    "\n",
    "# d. remove non-municipalities\n",
    "for val in ['Region','Province', 'All Denmark']: \n",
    "    I = area.municipality.str.contains(val)\n",
    "    area.drop(area[I].index, inplace=True)\n",
    "    \n",
    "area.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Writing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with reading in data, we have the corresponding functions for **writing data**:\n",
    "\n",
    "* CSV: `pd.to_csv()`\n",
    "* SAS: `pd.to_sas()`\n",
    "* Excel: `pd.to_excel()`\n",
    "* Stata: `pd.to_stata()`\n",
    "* Parquet: `pd.to_parquet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **save our dataset to CSV form**. We will set `index=False` to avoid saving the index (which does not mean anything here but can in other contexts be an annoying thing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long.to_csv('data/RAS200_long.csv', index=False)\n",
    "inc_long.to_csv('data/INDKP107_long.csv', index=False)\n",
    "area.to_csv('data/area.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Be cautious\n",
    "\n",
    "Code for cleaning data tend to get long and repetetive. But remember **DRY**! Errors crop up in data cleaning when you just copy blocks of code around. Avoid repetitions at all costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Summary\"></a>\n",
    "\n",
    "# 3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This lecture**: We have discussed\n",
    "\n",
    "1. The generel pandas framework (indexing, assigment, copies vs. views, functions)\n",
    "2. Loading and saving data\n",
    "3. Basic data cleaning (renaming, droping etc.)\n",
    "4. Wide $\\leftrightarrow$ long transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your work:** Before solving Problem Set 3 read through this notebook and play around with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next lecture:** Basic data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data exploration?:** Try out [dtale](https://github.com/man-group/dtale)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
