{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Today's topics:**  \n",
    "* Solving systems of equations\n",
    "    * Linear systems\n",
    "    * Non-linear systems\n",
    "    \n",
    "* Newton's method for root finding\n",
    "* Bisection for root finding\n",
    "* Symbolic math in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55102e",
   "metadata": {},
   "source": [
    "[Download on GitHub](https://github.com/NumEconCopenhagen/lectures-2022)\n",
    "\n",
    "[<img src=\"https://mybinder.org/badge_logo.svg\">](https://mybinder.org/v2/gh/NumEconCopenhagen/lectures-2022/master?urlpath=lab/tree/10/Solving_equations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397dd8f6",
   "metadata": {},
   "source": [
    "1. [Systems of linear equations](#Systems-of-linear-equations)\n",
    "2. [Non-linear equations - one dimensional](#Non-linear-equations---one-dimensional)\n",
    "3. [Solving non-linear equations (multi-dimensional)](#Solving-non-linear-equations-(multi-dimensional))\n",
    "4. [Solving equations by symbolic math](#Solving-equations-by-symbolic-math)\n",
    "5. [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10: Solving equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn about working with matrices and linear algebra (**scipy.linalg**), including solving systems of linear equations. You will learn to find roots of linear and non-linear equations both numerically (**scipy.optimize**) and symbolically (**sympy**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The algorithms written here are meant to be illustrative. The scipy implementations are always both the *fastest* and the *safest* choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Links:**\n",
    "\n",
    "1. **scipy.linalg:** [overview](https://docs.scipy.org/doc/scipy/reference/linalg.html) + [tutorial](https://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html)\n",
    "2. **sympy:** [overview](https://docs.sympy.org/latest/index.html) + [tutorial](https://docs.sympy.org/latest/tutorial/index.html#tutorial)\n",
    "3. **scipy.optimize:** [overview](https://docs.scipy.org/doc/scipy/reference/optimize.html) + [turtorial](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "from scipy import linalg\n",
    "from scipy import optimize\n",
    "import sympy as sm\n",
    "from IPython.display import display\n",
    "\n",
    "# local module for linear algebra\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numecon_linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Systems-of-linear-equations\"></a>\n",
    "\n",
    "# 1. Systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of economic models can be expressed as system of equations. Question is how to solve them?\n",
    "As a very easy example, just think of the market equilibrium when you have a supply curve and a demand curve.\n",
    "\n",
    "\n",
    "Consider a market, where suppliers have a **supply curve**\n",
    "$$\n",
    "q = 5 + \\frac{1}{3}p\n",
    "$$\n",
    "and consumers have a **demand curve** \n",
    "$$\n",
    "q = 10 - 2p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives rise to a linear system of equations\n",
    "$$\n",
    "\\begin{align}\n",
    "q-\\frac{1}{3}p &= 5 \\\\\n",
    "q+2p &= 10 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "When can put this into matrix notation $Ax=b$ by\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "1 & 2 \\\\ \n",
    "1 & -1/3 \\\\\n",
    "\\end{bmatrix} \\cdot \n",
    "\\begin{bmatrix} \n",
    "q \\\\ \n",
    "p \\\\ \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "10 \\\\ \n",
    "5 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Solving** for the equilibrium $x = [q, p]$ means solving $x$ in $Ax=b$. And we have done that if $A$ can be *inverted*: $x = A^{-1}b$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.0, 2.0],[1.0, -1/3]])\n",
    "b = np.array([10.0, 5.0])\n",
    "\n",
    "Ainv = linalg.inv(A)\n",
    "sol = Ainv @ b\n",
    "print(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Matrix equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, we consider **matrix equations** with $n$ equations and $n$ unknowns:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Ax = b \\Leftrightarrow\n",
    "\\begin{bmatrix}a_{11} & a_{12} & \\cdots & a_{1n}\\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix} & = \\begin{bmatrix}b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "b_{n}\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $A$ is a square parameter matrix, $b$ is a parameter vector, and $x$ is the vector of unknowns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific **example** could be:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "Ax = b \\Leftrightarrow\n",
    "\\begin{bmatrix} \n",
    "3 & 2 & 0 \\\\ \n",
    "1 & -1 & 0 \\\\\n",
    "0 & 5 & 1\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix} \n",
    "x_1 \\\\ \n",
    "x_2 \\\\\n",
    "x_3\n",
    "\\end{bmatrix} \\,=\\,\n",
    "\\begin{bmatrix} \n",
    "2 \\\\ \n",
    "4 \\\\\n",
    "-1\n",
    "\\end{bmatrix} \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to solve this?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3.0, 2.0, 0.0], [1.0, -1.0, 0], [0.0, 5.0, 1.0]])\n",
    "b = np.array([2.0, 4.0, -1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just guess.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ax = A@[2,-1,9] # @ is matrix multiplication\n",
    "print('A@x: ',Ax)\n",
    "\n",
    "if np.allclose(Ax,b): \n",
    "    print('solution found')\n",
    "else:\n",
    "    print('solution not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Various matrix operations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A.T # transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(A) # diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tril(A) # lower triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.triu(A) # upper triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = A.copy()\n",
    "np.fill_diagonal(B,0) # fill diagonal with zeros\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.inv(A) # inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.eigvals(A) # eigen values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Direct solution with Gauss-Jordan elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the column stacked matrix:\n",
    "\n",
    "$$\n",
    "X=[A\\,|\\,b]=\\begin{bmatrix}a_{11} & a_{12} & \\cdots & a_{1n} & b_{1}\\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n} & b_{2}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn} & b_{n}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the **row reduced echelon form** by performing row operations, i.e.\n",
    "\n",
    "1. Multiply row with constant\n",
    "2. Swap rows\n",
    "3. Add one row to another row,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "until the $A$ part of the matrix is the identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manually:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. stack\n",
    "X = np.column_stack((A,b))\n",
    "\n",
    "print('stacked:\\n',X)\n",
    "\n",
    "# b. row operations\n",
    "X[0,:] += 2*X[1,:]\n",
    "X[0,:] /= 5.0\n",
    "X[1,:] -= X[0,:]\n",
    "X[1,:] *= -1\n",
    "X[2,:] -= 5*X[1,:]\n",
    "print('\\nrow reduced echelon form:\\n',X)\n",
    "\n",
    "# c. print result (the last column in X in row reduced echelon form)\n",
    "print('\\nsolution \\n', X[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.column_stack((A,b))\n",
    "numecon_linalg.gauss_jordan(Y)\n",
    "print('solution',Y[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which can also be used to find the inverse if we stack with the identity matrix instead,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. construct stacked matrix\n",
    "Z = np.hstack((A,np.eye(3)))\n",
    "print('stacked:\\n',Z)\n",
    "\n",
    "# b. apply gauss jordan elimination\n",
    "numecon_linalg.gauss_jordan(Z)\n",
    "\n",
    "# b. find inverse\n",
    "inv_Z = Z[:,3:] # last 3 columns of Z in row reduced echelon form\n",
    "print('inverse:\\n',inv_Z)\n",
    "\n",
    "assert np.allclose(Z[:,3:]@A,np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Iteative Gauss-Seidel (+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can always decompose $A$ into additive lower and upper triangular matrices,\n",
    "\n",
    "$$\n",
    "A=L+U=\\begin{bmatrix}a_{11} & 0 & \\cdots & 0\\\\\n",
    "a_{21} & a_{22} & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{bmatrix}+\\begin{bmatrix}0 & a_{12} & \\cdots & a_{1n}\\\\\n",
    "0 & 0 & \\cdots & a_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "such that\n",
    "\n",
    "$$\n",
    "Ax=b\\Leftrightarrow \\underbrace{Lx}_{\\text{LHS}}=\\underbrace{b-Ux}_{\\text{RHS}}\n",
    "$$\n",
    "\n",
    "The idea and beauty of the algorithm is that we go from an identity, $Ax=b$, to an iteration on $x$. This is because the $x$ on the LHS above is **not** the same $x$ as on the RHS. It is an update! And if we keep making updates, we will eventually get the solution. See how below.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:** `gauss_seidel()`\n",
    "\n",
    "1. Choose tolerance $\\epsilon > 0$ and set $n=1$. Define the initial **guess** on $x$ denoted $x_0$.\n",
    "2. From $A$, get $L$ and $U$ as the lower and upper part.\n",
    "2. Set $\\tilde{x}= x_0$\n",
    "2. Given $\\tilde{x}$, calculate $y_n = (b-U\\tilde{x})$.\n",
    "2. Given $y_n$ solve for $x_{n}$ in the equation $Lx_{n} = y_n$.\n",
    "3. If $|x_{n}-\\tilde{x}|_{\\infty} < \\epsilon$ stop.   \n",
    "   Else, set $\\tilde{x} = x_{n}$ and $n=n+1$ and return to step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this smart? Because it relies on solving a system of equations, $Lx_n=y_n$, where $L$ is **lower triangular**. It is much easier to solve a system of a lower triangular matrix, because we can use **forward substitution**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the equation\n",
    "$$\n",
    "Lx = y \\Leftrightarrow \n",
    "\\begin{bmatrix}\n",
    "a_{11} & 0 & \\cdots & 0\\\\\n",
    "a_{21} & a_{22} & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{bmatrix} \n",
    "%\\cdot\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots\\\\\n",
    "x_n\n",
    "\\end{bmatrix} \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots\\\\\n",
    "y_n \\\\\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Solving directly by *forward substitution*:\n",
    ">\n",
    "> $x_1 = \\frac{y_1}{a_{11}}$\n",
    ">\n",
    ">Using $x_1$ one can find $x_2$\n",
    ">\n",
    "> $x_2 = \\frac{(y_2 - a_{21} x_1)}{a_{22}}$\n",
    ">\n",
    "> $x_3 = \\frac{(y_3 - a_{31} x_1 - a_{32} x_2)}{a_{33}}$\n",
    ">\n",
    "> etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Gauss-Seidel:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1,1,1])\n",
    "x =  numecon_linalg.gauss_seidel(A,b,x0)\n",
    "print('solution',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Convergence is not ensured unless the matrix is *diagonally dominant* or *symmetric* and *positive definite*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  numecon_linalg.gauss_seidel(A,b,x0,do_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4 Scipy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1:** Use `.solve()` (scipy chooses what happens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = linalg.solve(A, b)\n",
    "print(x1)\n",
    "assert np.all(A@x1 == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2:** Compute `.inv()` first and then solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ainv = linalg.inv(A)\n",
    "x2 = Ainv@b\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Computing the inverse is normally not a good idea due to numerical stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3:** Compute LU decomposition and then solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LU,piv = linalg.lu_factor(A) # decomposition (factorization)\n",
    "x3 = linalg.lu_solve((LU,piv),b)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detail:** `piv` contains information on a numerical stable reordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Comparisons\n",
    "\n",
    "1. `linalg.solve()` is the best choice for solving once.\n",
    "2. `linalg.lu_solve()` is the best choice when solving for multipe $b$'s for a fixed $A$ (the LU decomposition only needs to be done once).\n",
    "3. Gauss-Seidel is an alternative when e.g. only an approximate solution is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Details on LU factorization (+)\n",
    "\n",
    "When $A$ is *regular* (invertible), we can decompose it into a *lower unit triangular matrix*, $L$, and an *upper triangular matrix*, $U$:\n",
    "\n",
    "$$\n",
    "A= \\begin{bmatrix}a_{11} & a_{12} & \\cdots & a_{1n}\\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} & \\cdots & a_{nn}\n",
    "\\end{bmatrix} \n",
    "= L\\cdot U = \\begin{bmatrix}1 & 0 & \\cdots & 0\\\\\n",
    "l_{21} & 1 & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "l_{n1} & l_{n2} & \\cdots & 1\n",
    "\\end{bmatrix}\\cdot\\begin{bmatrix}u_{11} & u_{12} & \\cdots & u_{1n}\\\\\n",
    "0 & u_{22} & \\cdots & u_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & u_{nn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "By starting with the top row of the $upper$ part and the first $column$ of the lower part, we can work our way through using the definition of a matrix product. Note that we actively use the fact that there are 1s on the diagonal of the lower matrix.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\textrm{if    }&\\\\\n",
    " &i = 1: \\:\\: u_{1j} = a_{1j} \\:\\:\\:\\: (\\textit{top row is identical to that of A})\\\\\n",
    " &j = 1: \\:\\: l_{i1} = \\frac{a_{i1}}{u_{11}} \\\\\n",
    "\\textrm{else}&\\\\\n",
    "&u_{ij} = a_{ij} - \\sum_{k=1}^{i-1} u_{kj} l_{ik} \\\\\n",
    "%\\textrm{else  }\\:\\:\n",
    "&l_{ij} = \\frac{1}{u_{jj}} \\big( a_{ij} - \\sum_{k=1}^{j-1} u_{kj} l_{ik} \\big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "You can therefore get $L$ and $U$ by following steps:\n",
    "* First obtain row 1 of $U$. It's equal to row 1 of $A$. \n",
    "* Then get column 1 of $L$.\n",
    "* This will allow you to get $u_{2,2}$\n",
    "* Based on $u_{1,2},u_{2,1},u_{2,2},l_{1,1},l_{1,2}$ you can get $l_{3,2}$.\n",
    "* Keep working out subsequent $u_{ij}$ and $l_{ij}$ based on above formulas. \n",
    "\n",
    "The factorization implies that the equation system can be written\n",
    "\n",
    "$$ \n",
    "Ax = L(Ux) = b \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Algorithm:** `lu_solve()`  \n",
    "3 steps and you are done:\n",
    "1. Perform LU decomposition (factorization)\n",
    "2. Solve for $y$ in $Ly = b$ (using *forward substitution* - since we know that $y = Ux$, see above)\n",
    "3. Solve for $x$ in $Ux = y$ (using  *backward substitution* ~ going from bottom to top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L,U = numecon_linalg.lu_decomposition(A) # step 1\n",
    "y = numecon_linalg.solve_with_forward_substitution(L,b) # step 2\n",
    "x = numecon_linalg.solve_with_backward_substitution(U,y) # step 3\n",
    "print('A:\\n',A)\n",
    "print('L:\\n',L)\n",
    "print('\\nU:\\n',U)\n",
    "print('\\nsolution:',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relation to scipy:**\n",
    "\n",
    "1. Scipy use pivoting to improve numerical stability.\n",
    "2. Scipy is implemented much much better than here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Sparse matrices (+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sparse matrix:**   \n",
    "You may sometimes deal with a matrix that is really large, but **most** of the entries are 0s. Not uncommon in econometrics or large systems of equations.  \n",
    "\n",
    "In that case, you can save a lot of memory by removing all the 0s from memory and let Python only worry about the non-zero numbers. That of course requires a whole new set of routines for matrix operations, since the elements are no longer contiguous.    \n",
    "\n",
    "It can be worth it if about 70% of your matrix is just 0s. \n",
    "\n",
    "**scipy.linalg** allows you to solve systems of equations with sparse matrices. \n",
    "\n",
    "**Documentation:** [basics](https://docs.scipy.org/doc/scipy/reference/sparse.html) + [linear algebra](https://docs.scipy.org/doc/scipy/reference/sparse.linalg.html#module-scipy.sparse.linalg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a sparse matrix**, where most elements are on the diagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "S = sparse.lil_matrix((1000, 1000)) # 1000x1000 matrix with zeroes\n",
    "S.setdiag(np.random.rand(1000)) # some values on the diagonal\n",
    "S[200, :100] = np.random.rand(100) # some values in a row\n",
    "S[200:210, 100:200] = S[200, :100] # and the same value in some other rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plot of the values in the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_np = S.toarray() # conversion to numpy\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.matshow(S_np,cmap=plt.cm.binary);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solve it in four different ways:**\n",
    "\n",
    "1. Like it was not sparse\n",
    "2. Using the sparsity\n",
    "3. Using the sparsity + explicit factorization\n",
    "4. Iterative solver (similar to Gauss-Seidel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use some random numbers for right hand side of equation\n",
    "k = np.random.rand(1000) \n",
    "\n",
    "# a. solve \n",
    "t0 = time.time()\n",
    "x = linalg.solve(S_np,k)\n",
    "print(f'{\"solve\":12s}: {time.time()-t0:.5f} secs')\n",
    "\n",
    "# b. solve using sparse matrix algebra in spsolve\n",
    "t0 = time.time()\n",
    "x_alt = sparse.linalg.spsolve(S.tocsr(), k)\n",
    "print(f'{\"spsolve\":12s}: {time.time()-t0:.5f} secs')\n",
    "assert np.allclose(x,x_alt)\n",
    "      \n",
    "# c. solve with explicit factorization\n",
    "t0 = time.time()\n",
    "S_solver = sparse.linalg.factorized(S.tocsc())\n",
    "x_alt = S_solver(k)\n",
    "print(f'{\"factorized\":12s}: {time.time()-t0:.5f} secs')\n",
    "assert np.allclose(x,x_alt)\n",
    "      \n",
    "# d. solve with iterative solver (bicgstab)\n",
    "t0 = time.time()\n",
    "x_alt,_info = sparse.linalg.bicgstab(S,k,x0=1.001*x,tol=10**(-8))\n",
    "print(f'{\"bicgstab\":12s}: {time.time()-t0:.5f} secs')\n",
    "assert np.allclose(x,x_alt),x-x_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** \n",
    "\n",
    "1. Using the sparsity can be very important.\n",
    "2. Iterative solvers can be very very slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Non-linear-equations---one-dimensional\"></a>\n",
    "\n",
    "# 2. Non-linear equations - one dimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In economics, we really like setting **First Order Conditions** to 0. We do it every time we want to solve for optimal behavior..  \n",
    "\n",
    "Considering the FOCs as separate equations, finding optimal behavior is the same as finding the **root** of the FOCs.\n",
    "\n",
    "Therefore, we often want to **solve non-linear equations** on the form,\n",
    "\n",
    "$$ \n",
    "f(x) = 0, x \\in \\mathbb{R} \n",
    "$$\n",
    "\n",
    "There are 2 ways of going about: \n",
    "* **Using a derivative based method** Is more robust and takes fever steps.\n",
    "* **Derivative free methods** Less numerically stable, but does not require a gradient, so often easier to implement. \n",
    "\n",
    "Using derivate based methods is general preferable. BUT: formulating the gradient of a very complex function can be impossible and then derivative free methods is the way out.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple **example** of a function for our root finding:\n",
    "\n",
    "$$\n",
    "f(x) = -x^3 + 2x^2 + 4x + 30 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Derivative based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newton methods:**  \n",
    "Basic assumption: you know the function value *and* derivatives at a point $x_0$.   \n",
    "\n",
    "We now want to know what point $x^*$ gives a root of the function! \n",
    "\n",
    "**Importantly** since we are looking for a root, we know that $f(x^*) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a **first order** Taylor approximation of the function at a **new point** $x_k$ to search for the root of $f$:\n",
    "\n",
    "$$ \n",
    "f(x_k) \\approx f(x_0) + f^{\\prime}(x_0)(x_k-x_0)\n",
    "$$\n",
    "\n",
    "implying that if $x_k$ is the root, we have\n",
    "\n",
    "$$\n",
    "f(x_k) = 0 \\Leftrightarrow x_k = x_0 - \\frac{f(x_0)}{f^{\\prime}(x_0)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called **Newton's method**.   \n",
    "\n",
    "You can think of it as an **operator** on $x$ with respect to $f$ used to find the **nearest** root of $f$.  \n",
    "\n",
    "Let's call the operator $\\mathcal{N}_f$. If our current guess of a root to $f$ is $x_k$, we can get a new guess $x_{k+1}$ by applying $\\mathcal{N}_f(x_k)$\n",
    "* $x_1 = \\mathcal{N}_f(x_0) =  x_0 - \\frac{f(x_0)}{f^{\\prime}(x_0)}$\n",
    "* $x_2 = \\mathcal{N}_f(x_1)$\n",
    "* $x_3 = \\mathcal{N}_f(x_2)$\n",
    "* ...\n",
    "\n",
    "We have found a root when $|f(x_{k})| < \\epsilon$ which implies that the consecutive guesses also will become very close: $|x_{k+1}-x_k| < \\epsilon'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is **Halleys method** (see [derivation](https://mathworld.wolfram.com/HalleysMethod.html)), which uses\n",
    "\n",
    "$$\n",
    "x_k = x_0 - \\frac{f(x_0)}{f^{\\prime}(x_0)} \\Big[ 1-\\frac{f(x_0)}{f^{\\prime}(x_0)}\\frac{f^{\\prime\\prime}(x_0)}{2f^{\\prime}(x_0)} \\Big]^{-1} := \\mathcal{H}_f(x_0)\n",
    "$$\n",
    "\n",
    "making use of information from the **second derivative**. Note that if the second derivative is close to 0, Halley's method collapses into Newton's.  \n",
    "\n",
    "We denote this operator by $\\mathcal{H}_f(x_k)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:** `find_root()`\n",
    "\n",
    "1. Choose tolerance $\\epsilon > 0$, guess on $x_0$ and set $k = 0$.\n",
    "2. Calculate $f(x_k)$ and $f^{\\prime}(x_k)$. Also calculate $f^{\\prime\\prime}(x_k)$ when using Halley's method.\n",
    "3. If $|f(x_k)| < \\epsilon$ then stop.\n",
    "4. Calculate new candidate $x_{k+1} = \\mathcal{N}_f(x_k)$ when using Newtons.  \n",
    "   Otherwise, calculate $x_{k+1} = \\mathcal{H}_f(x_k)$ when using Halleys formula.\n",
    "5. Set $k = k + 1$ and return to step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root(x0,f,df,d2f=None,method='newton',max_iter=500,tol=1e-8,full_info=False):\n",
    "    \"\"\" find root\n",
    "        \n",
    "    Args:\n",
    "    \n",
    "        x0 (float): initial value\n",
    "        f (callable): function\n",
    "        df (callable): derivative\n",
    "        d2f (callable): second derivative\n",
    "        method (str): newton or halley\n",
    "        max_iter (int): maximum number of iterations\n",
    "        tol (float): tolerance\n",
    "        full_info (bool): controls information returned\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        x (float/ndarray): root (if full_info, all x tried)\n",
    "        i (int): number of iterations used\n",
    "        fx (ndarray): function values used (if full_info) \n",
    "        fpx (ndarray): derivative values used (if full_info)\n",
    "        fppx (ndarray): second derivative values used (if full_info)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    xs = []\n",
    "    fxs = []\n",
    "    dfxs = []\n",
    "    d2fxs = []\n",
    "    \n",
    "    # iterate\n",
    "    x = x0    \n",
    "    i = 0    \n",
    "    while True:\n",
    "        \n",
    "        # step 2: evaluate function and derivatives\n",
    "        fx = f(x)\n",
    "        dfx = df(x)\n",
    "        if method == 'halley':\n",
    "            d2fx = d2f(x)\n",
    "        \n",
    "        # step 3: check convergence\n",
    "        if abs(fx) < tol or i >= max_iter:\n",
    "            break\n",
    "            \n",
    "        # step 4: update x\n",
    "        if method == 'newton':\n",
    "            x_k = x - fx/dfx\n",
    "        elif method == 'halley':\n",
    "            a = fx/dfx\n",
    "            b = a*d2fx/(2*dfx)\n",
    "            x_k = x - a/(1-b)\n",
    "        \n",
    "        # step 5: increment counter\n",
    "        i += 1\n",
    "        \n",
    "        # step 6: store history\n",
    "        xs.append(x)\n",
    "        fxs.append(fx)\n",
    "        dfxs.append(dfx)\n",
    "        if method == 'halley':\n",
    "            d2fxs.append(d2fx)\n",
    "        \n",
    "        # step 7: apply new guess for x\n",
    "        x = x_k\n",
    "        \n",
    "    # return\n",
    "    if full_info:\n",
    "        return np.array(xs),i,np.array(fxs),np.array(dfxs),np.array(d2fxs)\n",
    "    else:\n",
    "        return x,i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The cell below contains a function for plotting the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_find_root(x0,f,fp,fpp=None,method='newton',xmin=-8,xmax=8,xn=100, vline = False):\n",
    "    \n",
    "    # a. find root and return all information \n",
    "    x,max_iter,fx,fpx,fppx = find_root(x0,f,df=fp,d2f=fpp,method=method,full_info=True)\n",
    "    \n",
    "    # b. compute function on grid\n",
    "    xvec = np.linspace(xmin,xmax,xn)\n",
    "    fxvec = f(xvec)\n",
    "    \n",
    "    # c. figure\n",
    "    def _figure(i):\n",
    "        \n",
    "        # i. approximation\n",
    "        if method == 'newton':\n",
    "            fapprox = fx[i] + fpx[i]*(xvec-x[i])\n",
    "        elif method == 'halley':\n",
    "            fapprox = fx[i] + fpx[i]*(xvec-x[i]) + fppx[i]/2*(xvec-x[i])**2  \n",
    "            \n",
    "        # ii. figure\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        \n",
    "        ax.plot(xvec,fxvec,label='function') # on grid\n",
    "        ax.plot(x[i],0,'o',color='blue',mfc='none',label='$x_{k}$')# now\n",
    "        ax.plot(x[i],fx[i],'o',color='black',label='$f(x_k)$') # now       \n",
    "        ax.plot(xvec,fapprox,label='approximation') # approximation\n",
    "        \n",
    "        if vline:\n",
    "            ax.axvline(x[i+1],ls='--',lw=1,color='black') # cross zero\n",
    "        \n",
    "        ax.axvline(0,ls='-',lw=1,color='black') # cross zero\n",
    "        ax.axhline(0, ls='-',lw=1,color='black')\n",
    "        #ax.plot(x[i+1],fx[i+1],'o',color='black',mfc='none',label='next')# next\n",
    "        ax.plot(x[i+1],0,'o',color='green',mfc='none',label='$x_{k+1}$')# next\n",
    "            \n",
    "        ax.legend(loc='lower right',facecolor='white',frameon=True)\n",
    "        ax.set_ylim([fxvec[0],fxvec[-1]])\n",
    "    \n",
    "    widgets.interact(_figure,\n",
    "        i=widgets.IntSlider(description=\"iterations\", min=0, max=max_iter-2, step=1, value=0)\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrating rootfinding by Newton's methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: -x**3 + 2*(x**2) + 4*x + 30 \n",
    "df = lambda x: -3*(x**2) + 4*x + 4\n",
    "df2 = lambda x: -6*x + 4 \n",
    "x0 = -5\n",
    "\n",
    "plot_find_root(x0,f,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Numerical derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you might not have the **analytical derivative**. Then, you can instead use the **numerical derivative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical derivative**  \n",
    "Define $\\Delta$ to be a small number, then we approximate the derivative by \n",
    "$$\n",
    " \\frac{df}{dx} \\approx \\frac{f(x+\\Delta) - f(x)}{\\Delta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. function\n",
    "#f = lambda x: 10*x**3 - x**2 -1\n",
    "\n",
    "# b. numerical derivative (forward)\n",
    "Δ = 1e-8\n",
    "fp_approx = lambda x: (f(x+Δ)-f(x))/Δ\n",
    "\n",
    "# b. find root\n",
    "x0 = -1.5\n",
    "x,i = find_root(x0,f,fp_approx,method='newton')\n",
    "print(f'iterations: {i}, root: {x}, f(x) = {f(x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happens if you increase the stepsize?   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: np.sin(x)\n",
    "gp = lambda x: np.cos(x)\n",
    "gpp = lambda x: -np.sin(x)\n",
    "\n",
    "x0 = 4.0\n",
    "plot_find_root(x0,g,gp,gpp,method='newton')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is the initial value important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Derivative free methods: Bisection\n",
    "\n",
    "Bisection is, like Newton's, an important root finding algorithm that you will find versions of in industry grade software like Matlab. It is not hard to get the idea behind!\n",
    "\n",
    "Look at the graph below. If $f(a) \\times f(b) < 0$ then there must be a root in between $a$ and $b$. Bisection just this idea iteratively together with the idea of using midpoints as in the **phone book search** from L09. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(0, 6, 100)\n",
    "ys = f(xs)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.plot(xs,ys) # on grid\n",
    "ax.axhline(0, ls='-',lw=1,color='black')\n",
    "ax.plot(xs[50],ys[50],'o',color='blue',label='$f(a)$') # now\n",
    "ax.plot(xs[80],ys[80],'o',color='green',label='$f(b)$') # now \n",
    "ax.legend(loc='lower left',facecolor='white',frameon=True);\n",
    "ax.set_ylim(-60,50);\n",
    "ax.set_xlim(1,6);\n",
    "ax.grid(b=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:** `bisection()`\n",
    "\n",
    "1. Set $a_0 = a$ and $b_0 = b$ where $f(a)$ and $f(b)$ has oposite sign, $f(a_0)f(b_0)<0$\n",
    "2. Compute $f(m_0)$ where $m_0 = (a_0 + b_0)/2$ is the midpoint.\n",
    "3. Determine the next sub-interval $[a_1,b_1]$:\n",
    "  * If $f(a_0)f(m_0) < 0$ (different signs) then $a_1 = a_0$ and $b_1 = m_0$ (i.e. focus on the range $[a_0,m_0]$).\n",
    "  * If $f(m_0)f(b_0) < 0$ (different signs) then $a_1 = m_0$ and $b_1 = b_0$ (i.e. focus on the range $[m_0,b_0]$).\n",
    "4. Repeat step 2 and step 3 until $f(m_n) < \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(f,a,b,max_iter=500,tol=1e-6,full_info=False):\n",
    "    \"\"\" bisection\n",
    "    \n",
    "    Solve equation f(x) = 0 for a <= x <= b.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        f (callable): function\n",
    "        a (float): left bound\n",
    "        b (float): right bound\n",
    "        max_iter (int): maximum number of iterations\n",
    "        tol (float): tolerance on solution\n",
    "        full_info (bool): controls information returned\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        m (float/ndarray): root (if full_info, all x tried)\n",
    "        i (int): number of iterations used\n",
    "        a (ndarray): left bounds used\n",
    "        b (ndarray): right bounds used\n",
    "        fm (ndarray): funciton values at midpoints\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # test inputs\n",
    "    if f(a)*f(b) >= 0:\n",
    "        print(\"bisection method fails.\")\n",
    "        return None\n",
    "    \n",
    "    # step 1: initialize\n",
    "    a_l = []\n",
    "    b_l = []\n",
    "    m_l = []\n",
    "    fm_l = []\n",
    "    \n",
    "    # step 2-4: main\n",
    "    i = 0\n",
    "    while i < max_iter:\n",
    "        \n",
    "        # step 2: midpoint and associated value\n",
    "        m = (a+b)/2\n",
    "        fm = f(m)\n",
    "        \n",
    "        # substep: update the lists of history \n",
    "        a_l.append(a)\n",
    "        b_l.append(b)\n",
    "        m_l.append(m)\n",
    "        fm_l.append(fm)\n",
    "        \n",
    "        # step 3: determine sub-interval\n",
    "        if abs(fm) < tol:\n",
    "            break        \n",
    "        elif f(a)*fm < 0:\n",
    "            b = m\n",
    "        elif f(b)*fm < 0:\n",
    "            a = m\n",
    "        else:\n",
    "            print(\"bisection method fails.\")\n",
    "            return None\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    if full_info:\n",
    "        # Returned lists are converted to np.arrays for good measure\n",
    "        return np.array(m_l), i, np.array(a_l), np.array(b_l), np.array(fm_l)\n",
    "    else:\n",
    "        return m,i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same result** as before, but **trade-off** between more iterations and no evaluation of derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,i = bisection(f,2,7)\n",
    "print(i,m,f(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The cell below contains a function for plotting the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bisection(f,a,b,xmin=-8,xmax=8,xn=100):\n",
    "    \n",
    "    # a. find root and return all information \n",
    "    res = bisection(f,a,b,full_info=True)\n",
    "    if res == None:\n",
    "        return\n",
    "    else:\n",
    "        m,max_iter,a,b,fm = res\n",
    "    \n",
    "    # b. compute function on grid\n",
    "    xvec = np.linspace(xmin,xmax,xn)\n",
    "    fxvec = f(xvec)\n",
    "    \n",
    "    # c. figure\n",
    "    def _figure(i):\n",
    "        \n",
    "        # ii. figure\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        \n",
    "        ax.plot(xvec,fxvec) # on grid\n",
    "        ax.axhline(y = 0, xmin=xmin, xmax=xmax, color = 'black')\n",
    "        ax.plot(m[i],fm[i],'o',color='black',label='current') # mid\n",
    "        ax.plot([a[i],b[i]],[fm[i],fm[i]],'--',color='green',label='range') # range\n",
    "        ax.axvline(a[i],ls='--',color='green')\n",
    "        ax.axvline(b[i],ls='--',color='green')        \n",
    "        \n",
    "        ax.legend(loc='lower right',facecolor='white',frameon=True)\n",
    "        ax.set_ylim([fxvec[0],fxvec[-1]])\n",
    "    \n",
    "    widgets.interact(_figure,\n",
    "        i=widgets.IntSlider(description=\"iterations\", min=0, max=max_iter-1, step=1, value=0)\n",
    "    );\n",
    "\n",
    "plot_bisection(f,-8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Note:** Bisection is not good at the final convergence steps. Generally true for methods not using derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy, naturally, has better implementations of the above algorithms. \n",
    "\n",
    "You will most likely want to go for these when doing your own model solution. Made by professionals... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newton:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,x0=-4,fprime=df,method='newton')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Halley:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,x0=-4,fprime=df,fprime2=df2,method='halley')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bisect:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,bracket=[-8,7],method='bisect')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **best choice** is the more advanced **Brent-method**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root_scalar(f,bracket=[-8,7],method='brentq')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Solving-non-linear-equations-(multi-dimensional)\"></a>\n",
    "\n",
    "# 3. Solving non-linear equations (multi-dimensional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider **solving non-linear equations** on the form,\n",
    "\n",
    "$$ \n",
    "f(\\boldsymbol{x}) = f(x_1,x_2,\\dots,x_k) = \\boldsymbol{0}, \\boldsymbol{x} \\in \\mathbb{R}^k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific **example** is:\n",
    "\n",
    "$$ \n",
    "h(\\boldsymbol{x})=h(x_{1,}x_{2})=\\begin{bmatrix}h_{1}(x_{1},x_{2})\\\\\n",
    "h_{2}(x_{1},x_{2})\n",
    "\\end{bmatrix}=\\begin{bmatrix}x_{1}+0.5(x_{1}-x_{2})^{3}-1\\\\\n",
    "x_{2}+0.5(x_{1}-x_{2})^{3}\n",
    "\\end{bmatrix}\\in\\mathbb{R}^{2} \n",
    "$$\n",
    "\n",
    "where the **Jacobian** is\n",
    "\n",
    "$$ \n",
    "\\nabla h(\\boldsymbol{x})=\\begin{bmatrix}\\frac{\\partial h_{1}}{\\partial x_{1}} & \\frac{\\partial h_{1}}{\\partial x_{2}}\\\\\n",
    "\\frac{\\partial h_{2}}{\\partial x_{1}} & \\frac{\\partial h_{2}}{\\partial x_{2}}\n",
    "\\end{bmatrix}=\\begin{bmatrix}1+1.5(x_{1}-x_{2})^{2} & -1.5(x_{1}-x_{2})^{2}\\\\\n",
    "-1.5(x_{2}-x_{1})^{2} & 1+1.5(x_{2}-x_{1})^{2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    y = np.zeros(2)\n",
    "    y[0] = x[0]+0.5*(x[0]-x[1])**3-1.0\n",
    "    y[1] = x[1]+0.5*(x[1]-x[0])**3\n",
    "    return y\n",
    "\n",
    "def hp(x):\n",
    "    y = np.zeros((2,2))\n",
    "    y[0,0] = 1+1.5*(x[0]-x[1])**2\n",
    "    y[0,1] = -1.5*(x[0]-x[1])**2\n",
    "    y[1,0] = -1.5*(x[1]-x[0])**2\n",
    "    y[1,1] = 1+1.5*(x[1]-x[0])**2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving a multidimensional system of equations follows the exact same strategy as finding the root of a single equation - **except** we are now working with the Jacobian instead of a single derivative. \n",
    "\n",
    "Same as Newton's method in one dimension, but with the following **update step**:\n",
    "\n",
    "$$ \n",
    "\\boldsymbol{x}_{n+1} = \\boldsymbol{x_n} - [ \\nabla h(\\boldsymbol{x_n})]^{-1} f(\\boldsymbol{x_n})\n",
    "$$\n",
    "\n",
    "**Notice** something important here: $[ \\nabla h(\\boldsymbol{x_n})]^{-1}$ is a matrix inverse! As you saw above, these are costly to perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root_multidim(x0,f,fp,max_iter=500,tol=1e-8):\n",
    "    \"\"\" find root\n",
    "        \n",
    "    Args:\n",
    "    \n",
    "        x0 (float): initial value\n",
    "        f (callable): function\n",
    "        fp (callable): derivative\n",
    "        max_iter (int): maximum number of iterations\n",
    "        tol (float): tolerance\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        x (float): root\n",
    "        i (int): number of iterations used\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    x = x0\n",
    "    i = 0\n",
    "    \n",
    "    # iterate\n",
    "    while i < max_iter:\n",
    "        \n",
    "        # step 2: function and derivatives\n",
    "        fx = f(x)\n",
    "        fpx = fp(x)\n",
    "        \n",
    "        # step 3: check convergence\n",
    "        if max(abs(fx)) < tol:\n",
    "            break\n",
    "            \n",
    "        # step 4: update x - here is where you want to use a sensible algorithm for inversion\n",
    "        fpx_inv = linalg.inv(fpx)        \n",
    "        x = x - fpx_inv@fx\n",
    "        \n",
    "        # step 5: increment counter\n",
    "        i += 1\n",
    "        \n",
    "    return x,i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test algorithm:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0,0])\n",
    "x,i = find_root_multidim(x0,h,hp)\n",
    "print(i,x,h(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Using Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should use profesionally implemented routines for optimizing your models!   \n",
    "There exist a lot of efficient algorithms for finding roots in multiple dimensions. The default **scipy** choice is something called ***hybr***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With the Jacobian:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root(h,x0,jac=hp)\n",
    "print(result)\n",
    "print('\\nx =',result.x,', h(x) =',h(result.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without the Jacobian:** (numerical derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = optimize.root(h,x0)\n",
    "print(result)\n",
    "print('\\nx =',result.x,', h(x) =',h(result.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Solving-equations-by-symbolic-math\"></a>\n",
    "\n",
    "# 4. Solving equations by symbolic math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like your old TI calculator and Mathmatica, Python has a module for solving equations symbolically. Which also means solving them **exactly**. No numerical errors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Solve consumer problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider solving the following problem:\n",
    "\n",
    "$$ \n",
    "\\max_{x_1,x_2} x_1^{\\alpha} x_2^{\\beta} \\text{ s.t. } p_1x_1 + p_2x_2 = I \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = sm.symbols('x_1') # x1 is a Python variable representing the symbol x_1\n",
    "x2 = sm.symbols('x_2')\n",
    "alpha = sm.symbols('alpha')\n",
    "beta = sm.symbols('beta')\n",
    "p1 = sm.symbols('p_1')\n",
    "p2 = sm.symbols('p_2')\n",
    "I = sm.symbols('I')\n",
    "\n",
    "print('x1 is of type: ', type(x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define objective and budget constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the equation as if it was regular code\n",
    "objective = x1**alpha*x2**beta\n",
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the budget constraint as an equality\n",
    "budget_constraint = sm.Eq(p1*x1+p2*x2,I)\n",
    "budget_constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve in **four steps**:\n",
    "\n",
    "1. **Isolate** $x_2$ from the budget constraint\n",
    "2. **Substitute** in $x_2$\n",
    "3. **Take the derivative** wrt. $x_1$\n",
    "4. **Solve the FOC** for $x_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Isolate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate x2 on LHS\n",
    "x2_from_con = sm.solve(budget_constraint, x2)\n",
    "x2_from_con[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Substitute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_subs = objective.subs(x2, x2_from_con[0])\n",
    "objective_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Take the derivative**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foc = sm.diff(objective_subs, x1)\n",
    "foc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Solve the FOC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = sm.solve(sm.Eq(foc,0), x1)\n",
    "sol[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> An alternative is `sm.solveset()`, which will be the default in the future, but it is still a bit immature in my view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Solve the consumer problem with quasi-linear preferences,\n",
    "\n",
    "$$ \\max_{x_1,x_2} \\sqrt{x_1} + \\gamma x_2 \\text{ s.t. } p_1x_1 + p_2x_2 = I $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gamma = sm.symbols('gamma')\n",
    "objective_alt = sm.sqrt(x1) + gamma*x2\n",
    "objective_alt_subs = objective_alt.subs(x2,x2_from_con[0])\n",
    "foc_alt = sm.diff(objective_alt_subs,x1)\n",
    "sol_alt = sm.solve(foc_alt,x1)\n",
    "sol_alt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Use solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LaTex:** Print in LaTex format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sm.latex(sol[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn solution into Python function\n",
    "\n",
    "Sympy can do a fantastic trick!  \n",
    "\n",
    "Once you have the solution of your equation, this can be **turned into a Python function**. Thus you can use the solution on arrays. It's called lambdification (think \"lambda functions\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example. 1st element of lambdify: a tuple of symbols to be used. 2nd element: the expression used on the symbols.  \n",
    "x = sm.symbols('x')\n",
    "x_square = sm.lambdify(args = (x), expr = x**2)\n",
    "x_square(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function out of the solution by providing the \"expression\" you want (ie the solution) and the inputs to the expression in a tuple. \n",
    "sol_func = sm.lambdify(args = (p1, I, alpha, beta), expr = sol[0])\n",
    "\n",
    "# Run solution. DO NOT overwrite the SYMBOLS (I,alpha,beta) with numeric data\n",
    "p1_vec = np.array([1.2,3,5,9])\n",
    "I_val = 10\n",
    "alpha_val = 0.5\n",
    "beta_val = 0.5\n",
    "\n",
    "# Run solution function with vector of prices\n",
    "demand_p1 = sol_func(p1_vec, I_val, alpha_val, beta_val)\n",
    "\n",
    "for d in demand_p1:\n",
    "    print(f'demand: {d:1.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing properties of the solution (expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is demand always positive?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the computer the **information** we have. I.e. that $p_1$, $p_2$, $\\alpha$, $\\beta$, $I$ are all strictly positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [p1,p2,alpha,beta,I]:\n",
    "    sm.assumptions.assume.global_assumptions.add(sm.Q.positive(var)) # var is always positive\n",
    "sm.assumptions.assume.global_assumptions    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ask** the computer a **question**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = sm.ask(sm.Q.positive(sol[0]))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the assumption that $p_1 > 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.assumptions.assume.global_assumptions.remove(sm.Q.positive(p1))\n",
    "answer = sm.ask(sm.Q.positive(sol[0]))\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clear all assumptions we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.assumptions.assume.global_assumptions.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 More features of symbolic math (mixed goodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.symbols('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivatives:** Higher order derivatives are also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.Derivative('x**4',x,x, evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.diff('x**4',x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = sm.Derivative('x**4',x,x)\n",
    "expr.doit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With two variables\n",
    "y = sm.symbols('y')\n",
    "sm.diff('(x**2)*log(y)*exp(y)',x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrals:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.Integral(sm.exp(-x), (x, 0, sm.oo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.integrate(sm.exp(-x), (x, 0, sm.oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limits:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sm.symbols('c')\n",
    "rho = sm.symbols('rho')\n",
    "\n",
    "# Write up the definition of your limit\n",
    "sm.Limit((c**(1-rho)-1)/(1-rho),rho,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the limit\n",
    "sm.limit((c**(1-rho)-1)/(1-rho),rho,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.Integer(7)/sm.Integer(3)\n",
    "Y = sm.Integer(3)/sm.Integer(8)\n",
    "display(X)\n",
    "display(Y)\n",
    "Z = 3\n",
    "(X*Y)**Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simplify:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = sm.sin(x)**2 + sm.cos(x)**2\n",
    "display(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.simplify(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solve multiple equations at once:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.symbols('x')\n",
    "y = sm.symbols('y')\n",
    "Eq1 = sm.Eq(x**2+y-2,0)\n",
    "Eq2 = sm.Eq(y**2-4,0)\n",
    "display(Eq1)\n",
    "display(Eq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the system\n",
    "sol = sm.solve([Eq1,Eq2],[x,y])\n",
    "\n",
    "# print all solutions\n",
    "for xy in sol:\n",
    "    print(f'(x,y) = ({xy[0]},{xy[1]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Solving matrix equations symbolically (+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Ax = b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct a symbolic matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sm = numecon_linalg.construct_sympy_matrix(['11','12','21','22','32','33']) # somewhat complicated function\n",
    "A_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the inverse symbolically:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sm_inv = A_sm.inv()\n",
    "A_sm_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill in the numeric values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv_num = numecon_linalg.fill_sympy_matrix(A_sm_inv,A) # somewhat complicated function\n",
    "x = A_inv_num@b\n",
    "print('solution:',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The inverse multiplied by the determinant looks nicer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sm_det = A_sm.det()\n",
    "A_sm_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sm_inv_raw = sm.simplify(A_sm_inv*A_sm_det)\n",
    "A_sm_inv_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Newtons method and symbolic math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another use case of our symbolic math\n",
    "x = sm.symbols('x')\n",
    "func = -x**3 + 2*x**2 + 4*x + 30\n",
    "dfunc = sm.diff(func, x)\n",
    "d2func = sm.diff(dfunc, x)\n",
    "\n",
    "display(func)\n",
    "display(dfunc)\n",
    "display(d2func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambdify\n",
    "f = sm.lambdify((x), func)\n",
    "df = sm.lambdify((x), dfunc)\n",
    "d2f = sm.lambdify((x), d2func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, i = find_root(-2,f,df,method='newton', full_info=False)\n",
    "print(f'Iterations: {i}, root = {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the **flat region** tricks both Newton's and Halley's methods.  \n",
    "Especially Halley's method does better if it is started to the right of the root rather than to the left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_find_root(8,f,df,method='newton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,i = find_root(-5,f,df,d2f,method='halley')\n",
    "print(i,x,f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_find_root(-2,f,df,d2f,method='halley', vline='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sympy** can actually tell us that there are many solutions to an equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.symbols('x')\n",
    "sm.solveset(sm.sin(x),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Summary\"></a>\n",
    "\n",
    "# 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This lecture:**\n",
    "\n",
    "1. Solving matrix equations (directly, decomposition, iterative)\n",
    "2. Symbollic solutions (substitution, derivative, solution)\n",
    "3. Root-finding (one dimension, multiple dimensions, Newton's method, biscetion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your work:** Play around with the code in this notebook before solving the problem set. Especially, try out the various scipy functions used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next lecture:** Numerical optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
